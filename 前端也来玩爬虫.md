# 简介

## 什么是爬虫？

> 百科：网络爬虫，是一种自动获取网页内容的程序。是搜索引擎的重要组成部分，因此搜索引擎优化很大程度上就是针对爬虫而做出的优化。

简单的说，爬虫就是通过程序代码，获取一些URL对应的网页的HTML内容，进行分析，从而发现更多网页，并解析网页，拿到自己需要的数据，进行保存，和进一步利用。

## 有什么用？

### 1. 搜索引擎
> 搜索引擎派出一个能够在网上发现新网页并抓文件的程序，这个程序通常称之为蜘蛛（Spider）。搜索引擎从已知的数据库出发，就像正常用户的浏览器一样访问这些网页并抓取文件。搜索引擎通过这些爬虫去爬互联网上的外链，从这个网站爬到另一个网站，去跟踪网页中的链接，访问更多的网页，这个过程就叫爬行。这些新的网址会被存入数据库等待搜索。

### 2. 其他
> 某电影评分网站，没提供按评分高低排序功能？自己抓下来，自己排。

> 某网站关注的女神，想分析一下女神的过往动态，达到一些不可描述的目的？抓动态，做图表。

> 某旅行服务网站经常爆出酒店机票bug价，却发现不及时，错过几个亿？抓抓抓，监控！

> 某电影资源网站，广告多，打开找电影太麻烦？直接抓下载链接。

> 公司分析竞争对手网站？二话不说，就是爬。

所以说，爬虫也是让你掌握的技术，帮你解决工作之外的问题的一个很好的工具。

## 一般流程

- 抓：把想要的页面抓回来先；
- 存：一般，会把抓回来的内容，先存下来再分析；
- 解：解析抓回来的内容，提取有用的东西；
- 示：把有用的东西，按需求，处理成直观的内容，进行输出；

# 开始：用NodeJS做一个简单的爬虫

## 第一步：抓

首先我们需要一个idea，做个什么爬虫呢？想了半天，最终决定去爬一下豆瓣读书（其中的一个分类），看看计算机相关的书籍有多少，并分析一下，跟前端相关的有多少，评分如何，价格如何等等。

那么，把大象装冰箱统共需要几步？

1. 需要一个URL。

于是打开豆瓣网站，定位到计算机相关书籍页面，URL如下：

[https://read.douban.com/kind/105?sort=hot&promotion_only=False&min_price=None&works_type=None&max_price=None](https://read.douban.com/kind/105?sort=hot&promotion_only=False&min_price=None&works_type=None&max_price=None)

有了URL，接下来要用代码抓页面了，如何做呢？

2. 在Node环境里解析URL

> 简单起见，本文就不说抓到的数据怎么存储了，存文件，存数据库，或者别的什么方式，大家都可以自由选择，这部分不是重点。所以，我们启动一个server，直接把抓到的东西进行分析展示。

这样的话，我们需要`server`：

新建一个文件夹，取名：`read.douban.com`

新建`js`文件：

```javascript
// server.js
const http = require('http')
const start = () => {
    let onRequest = async (req, res) => {
        res.writeHead(200, {
            'Content-Type': 'text/html; charset=UTF-8',
        })
        res.write('' || 'ERR')
        res.end()
    }    
    http.createServer(onRequest).listen(3000)
    console.log('server started!')
}

module.exports = {start}
```
```javascript
// index.js
const server = require('./server')
server.start()
```
代码很简单，就不过多解释了。




我们需要一个`server`

由于一些网站有一些简单的反爬虫处理，所以我们直接用`phantom`这个工具，来访问URL